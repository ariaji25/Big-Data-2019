{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ THE DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the csv data of breast-cancer drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"breast-cancer.csv\")\n",
    "# normalize_data = data.dropna(axis=\"rows\", how=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the \"diagnosis\" column to be the label/class of the data and save to \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"diagnosis\"] \n",
    "y.replace((\"M\", \"B\"),(0,1), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all columns is not useable to be feature of the data, and save the features to \"x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"Unnamed: 32\", axis=1)\n",
    "data = data.drop(\"id\", axis=1)\n",
    "x = data.drop(\"diagnosis\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset to be training datas and testing datas (90:10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x,y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasification with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score :   100.0 %\n"
     ]
    }
   ],
   "source": [
    "# knn\n",
    "from sklearn.neighbors import KNeighborsClassifier #library KNN\n",
    "# make teh knn object with k = 1\n",
    "clf = KNeighborsClassifier(n_neighbors=1) \n",
    "# fit the training data\n",
    "clf.fit(train_x, train_y)\n",
    "# show score or acuration from training or learning process\n",
    "print(\"Score :  \", clf.score(train_x, train_y) * 100, \"%\")#training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score : 98.24561403508771 %\n"
     ]
    }
   ],
   "source": [
    "# try predict the testing data\n",
    "predict = clf.predict(test_x)\n",
    "true_label = np.array(test_y)\n",
    "print(\"Test Score :\", clf.score(test_x, test_y)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 0.02\n",
      "Residual sum of squares (MSE): 0.02\n",
      "R2-score: 0.92\n"
     ]
    }
   ],
   "source": [
    "# count score of testing process\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(predict - true_label)))\n",
    "print(\"Residual sum of squares (MSE): %.2f\" % np.mean((predict - true_label) ** 2))\n",
    "print(\"R2-score: %.2f\" % r2_score(predict , true_label) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "ann = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "ann.fit(train_x, train_y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.380859375"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.score(train_x,train_y)\n",
    "# ann.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aria/.local/lib/python3.7/site-packages/pandas/core/generic.py:6586: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Test.csv\")\n",
    "normalize_data_test = data.dropna(axis=\"rows\", how=\"any\")\n",
    "y_test = normalize_data_test[\"Outlet_Type\"] \n",
    "y_test.replace((\"Supermarket Type1\", \"Supermarket Type2\"),(0,1), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = normalize_data_test.drop(\"Item_Identifier\", axis=1)\n",
    "x_test = x_test.drop(\"Item_Fat_Content\", axis=1)\n",
    "x_test = x_test.drop(\"Item_Type\", axis=1)\n",
    "x_test = x_test.drop(\"Outlet_Identifier\", axis=1)\n",
    "x_test = x_test.drop(\"Outlet_Establishment_Year\", axis=1)\n",
    "x_test = x_test.drop(\"Outlet_Size\", axis=1)\n",
    "x_test = x_test.drop(\"Outlet_Location_Type\", axis=1)\n",
    "x_test = x_test.drop(\"Outlet_Type\", axis=1)\n",
    "x_test = x_test.drop(\"Item_Visibility\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as nm\n",
    "label = nm.array(y_test)\n",
    "predict = nm.array(ann.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8005808325266215"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
